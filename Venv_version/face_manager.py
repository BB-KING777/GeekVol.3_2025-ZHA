"""
é¡”èªè­˜ç®¡ç†ãƒ„ãƒ¼ãƒ« - ä¿®æ­£ç‰ˆï¼ˆWindowså¯¾å¿œï¼‰
"""
import argparse
import sys
from pathlib import Path
import json
import cv2
import time
import threading
from datetime import datetime

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent))

import config


def calculate_blur_score(image: np.ndarray) -> float:
    """ç”»åƒã®ãƒ–ãƒ¬ï¼ˆã¼ã‹ã—ï¼‰ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ï¼ˆãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³åˆ†æ•£ï¼‰"""
    try:
        # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image
        
        # ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³ãƒ•ã‚£ãƒ«ã‚¿ã§ã‚¨ãƒƒã‚¸æ¤œå‡º
        laplacian = cv2.Laplacian(gray, cv2.CV_64F)
        
        # åˆ†æ•£ã‚’è¨ˆç®—ï¼ˆé«˜ã„ã»ã©é®®æ˜ï¼‰
        blur_score = laplacian.var()
        
        return blur_score
    except Exception as e:
        print(f"ãƒ–ãƒ¬ã‚¹ã‚³ã‚¢è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
        return 0.0

def calculate_brightness_score(image: np.ndarray) -> float:
    """ç”»åƒã®æ˜ã‚‹ã•ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
    try:
        # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image
        
        # å¹³å‡æ˜åº¦ã‚’è¨ˆç®—
        brightness = np.mean(gray)
        
        return brightness
    except Exception as e:
        print(f"æ˜ã‚‹ã•ã‚¹ã‚³ã‚¢è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
        return 0.0

def detect_face_quality(image: np.ndarray) -> Tuple[bool, float, tuple]:
    """é¡”ã®å“è³ªã‚’è©•ä¾¡ï¼ˆé¡”æ¤œå‡º + ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯ï¼‰"""
    try:
        # OpenCVã®é¡”æ¤œå‡ºå™¨ã‚’ä½¿ç”¨
        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        
        # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # é¡”æ¤œå‡º
        faces = face_cascade.detectMultiScale(
            gray,
            scaleFactor=1.1,
            minNeighbors=5,
            minSize=(50, 50)  # æœ€å°é¡”ã‚µã‚¤ã‚º
        )
        
        if len(faces) == 1:
            # 1ã¤ã®é¡”ãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆ
            x, y, w, h = faces[0]
            face_area = w * h
            image_area = image.shape[0] * image.shape[1]
            face_ratio = face_area / image_area
            
            return True, face_ratio, (x, y, w, h)
        elif len(faces) > 1:
            # è¤‡æ•°ã®é¡”ãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆ
            return False, 0.0, None
        else:
            # é¡”ãŒæ¤œå‡ºã•ã‚Œãªã„å ´åˆ
            return False, 0.0, None
            
    except Exception as e:
        print(f"é¡”å“è³ªæ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")
        return False, 0.0, None

def record_video_for_registration(person_id: str, name: str, duration: int = 10) -> str:
    """ç™»éŒ²ç”¨å‹•ç”»ã‚’æ’®å½±"""
    print(f"\n{name}ã•ã‚“ã®å‹•ç”»ã‚’{duration}ç§’é–“æ’®å½±ã—ã¾ã™ã€‚")
    print("æ’®å½±ä¸­ã¯ä»¥ä¸‹ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ï¼š")
    print("1. ã‚«ãƒ¡ãƒ©ã‚’æ­£é¢ã«å‘ã‘ã¦åº§ã‚‹")
    print("2. ã‚†ã£ãã‚Šã¨å·¦å³ã«é¡”ã‚’å‘ã‘ã‚‹")
    print("3. ä¸Šä¸‹ã«ã‚‚å°‘ã—é¡”ã‚’å‹•ã‹ã™")
    print("4. é€”ä¸­ã§ç¬‘é¡”ã‚‚ä½œã£ã¦ãã ã•ã„")
    print("\næ“ä½œæ–¹æ³•:")
    print("- Enterã‚­ãƒ¼: æ’®å½±é–‹å§‹")
    print("- Escã‚­ãƒ¼: ã‚­ãƒ£ãƒ³ã‚»ãƒ«")
    
    videos_dir = config.DATA_DIR / "registration_videos" / person_id
    videos_dir.mkdir(parents=True, exist_ok=True)
    
    # ã‚«ãƒ¡ãƒ©åˆæœŸåŒ–ï¼ˆWindowså¯¾å¿œï¼‰
    camera = cv2.VideoCapture(0, cv2.CAP_DSHOW)
    
    if not camera.isOpened():
        print("âŒ ã‚«ãƒ¡ãƒ©ã‚’é–‹ã‘ã¾ã›ã‚“ã§ã—ãŸ")
        return None
    
    # ã‚«ãƒ¡ãƒ©è¨­å®š
    camera.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    camera.set(cv2.CAP_PROP_FPS, 30)
    
    # å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    video_path = videos_dir / f"{person_id}_{timestamp}.avi"
    
    # å‹•ç”»æ›¸ãè¾¼ã¿è¨­å®š
    fourcc = cv2.VideoWriter_fourcc(*'MJPG')
    out = cv2.VideoWriter(str(video_path), fourcc, 30.0, (640, 480))
    
    print(f"\nğŸ“¹ ã‚«ãƒ¡ãƒ©ã‚’èµ·å‹•ã—ã¾ã—ãŸã€‚Enterã‚­ãƒ¼ã§æ’®å½±é–‹å§‹...")
    
    # æ’®å½±æº–å‚™ç”»é¢
    recording = False
    start_time = None
    
    try:
        while True:
            ret, frame = camera.read()
            if not ret:
                print("âŒ ãƒ•ãƒ¬ãƒ¼ãƒ ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
                break
            
            # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å·¦å³åè»¢ï¼ˆé¡åƒè¡¨ç¤ºï¼‰
            frame = cv2.flip(frame, 1)
            display_frame = frame.copy()
            
            # æ’®å½±çŠ¶æ…‹ã«å¿œã˜ãŸè¡¨ç¤º
            if not recording:
                # æ’®å½±å‰
                cv2.putText(display_frame, f"Person: {name}", 
                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
                cv2.putText(display_frame, "Press ENTER to start recording", 
                           (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
                cv2.putText(display_frame, "ESC: Cancel", 
                           (10, display_frame.shape[0] - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
            else:
                # æ’®å½±ä¸­
                elapsed = time.time() - start_time
                remaining = max(0, duration - elapsed)
                
                # éŒ²ç”»ä¸­è¡¨ç¤º
                cv2.circle(display_frame, (30, 30), 15, (0, 0, 255), -1)  # èµ¤ã„éŒ²ç”»ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿
                cv2.putText(display_frame, "RECORDING", 
                           (60, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
                
                # æ®‹ã‚Šæ™‚é–“è¡¨ç¤º
                cv2.putText(display_frame, f"Time: {remaining:.1f}s", 
                           (10, 80), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
                
                # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
                progress_width = int((elapsed / duration) * 620)
                cv2.rectangle(display_frame, (10, 100), (630, 120), (100, 100, 100), 2)
                cv2.rectangle(display_frame, (10, 100), (10 + progress_width, 120), (0, 255, 0), -1)
                
                # æ’®å½±ã‚¬ã‚¤ãƒ‰
                phase = int(elapsed) % 6
                guides = [
                    "Look straight ahead",
                    "Turn slightly left", 
                    "Turn slightly right",
                    "Look up a little",
                    "Look down a little",
                    "Smile!"
                ]
                cv2.putText(display_frame, guides[phase], 
                           (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)
                
                # å‹•ç”»ã«æ›¸ãè¾¼ã¿ï¼ˆåè»¢ã—ãªã„å…ƒã®ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰
                original_frame = cv2.flip(frame, 1)  # 2å›åè»¢ã§å…ƒã«æˆ»ã™
                out.write(original_frame)
                
                # æ™‚é–“çµ‚äº†ãƒã‚§ãƒƒã‚¯
                if elapsed >= duration:
                    print(f"âœ… {duration}ç§’é–“ã®æ’®å½±ãŒå®Œäº†ã—ã¾ã—ãŸ")
                    break
            
            # ä¸­å¤®ã«æ’®å½±ã‚¨ãƒªã‚¢ã‚’è¡¨ç¤º
            h, w = display_frame.shape[:2]
            cv2.rectangle(display_frame, (w//4, h//4), (3*w//4, 3*h//4), (0, 255, 0), 2)
            
            cv2.imshow(f'Video Registration - {name}', display_frame)
            
            # ã‚­ãƒ¼å…¥åŠ›å‡¦ç†
            key = cv2.waitKey(1) & 0xFF
            
            if key == 13:  # Enterã‚­ãƒ¼
                if not recording:
                    recording = True
                    start_time = time.time()
                    print(f"ğŸ“¹ æ’®å½±é–‹å§‹: {duration}ç§’é–“")
                
            elif key == 27:  # Escapeã‚­ãƒ¼
                print("âŒ æ’®å½±ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
                video_path = None
                break
    
    except KeyboardInterrupt:
        print("âŒ æ’®å½±ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        video_path = None
    
    finally:
        camera.release()
        out.release()
        cv2.destroyAllWindows()
        print("ğŸ“· ã‚«ãƒ¡ãƒ©ã‚’åœæ­¢ã—ã¾ã—ãŸ")
    
    return str(video_path) if video_path and video_path.exists() else None

def extract_best_frames_from_video(video_path: str, person_id: str, target_count: int = 5) -> List[str]:
    """å‹•ç”»ã‹ã‚‰æœ€é©ãªãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æŠ½å‡º"""
    print(f"\nğŸ“Š å‹•ç”»ã‹ã‚‰æœ€é©ãªãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æŠ½å‡ºä¸­...")
    print("è©•ä¾¡åŸºæº–: ãƒ–ãƒ¬ã€æ˜ã‚‹ã•ã€é¡”ã‚µã‚¤ã‚ºã€é¡”ã®å‘ã")
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    frames_dir = config.DATA_DIR / "registration_photos" / person_id
    frames_dir.mkdir(parents=True, exist_ok=True)
    
    # å‹•ç”»ã‚’é–‹ã
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"âŒ å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã‘ã¾ã›ã‚“ã§ã—ãŸ: {video_path}")
        return []
    
    # å‹•ç”»æƒ…å ±å–å¾—
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    duration = total_frames / fps if fps > 0 else 0
    
    print(f"å‹•ç”»æƒ…å ±: {total_frames}ãƒ•ãƒ¬ãƒ¼ãƒ , {fps:.1f}FPS, {duration:.1f}ç§’")
    
    # ãƒ•ãƒ¬ãƒ¼ãƒ è©•ä¾¡çµæœã‚’ä¿å­˜
    frame_evaluations = []
    
    frame_count = 0
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        # 5ãƒ•ãƒ¬ãƒ¼ãƒ ã«1å›è©•ä¾¡ï¼ˆå‡¦ç†é€Ÿåº¦å‘ä¸Šï¼‰
        if frame_count % 5 == 0:
            # å„ç¨®å“è³ªã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
            blur_score = calculate_blur_score(frame)
            brightness_score = calculate_brightness_score(frame)
            has_face, face_ratio, face_bbox = detect_face_quality(frame)
            
            # å“è³ªè©•ä¾¡
            quality_score = 0.0
            
            if has_face:
                # ãƒ–ãƒ¬ã‚¹ã‚³ã‚¢ï¼ˆé«˜ã„ã»ã©è‰¯ã„ï¼‰- æ­£è¦åŒ–
                blur_normalized = min(blur_score / 500.0, 1.0)  # 500ä»¥ä¸Šã§æº€ç‚¹
                
                # æ˜ã‚‹ã•ã‚¹ã‚³ã‚¢ï¼ˆ70-180ãŒæœ€é©ï¼‰
                brightness_normalized = 1.0 - abs(brightness_score - 125) / 125.0
                brightness_normalized = max(0.0, brightness_normalized)
                
                # é¡”ã‚µã‚¤ã‚ºã‚¹ã‚³ã‚¢ï¼ˆ0.1-0.4ãŒæœ€é©ï¼‰
                face_size_normalized = 1.0
                if face_ratio < 0.05:  # é¡”ãŒå°ã•ã™ãã‚‹
                    face_size_normalized = face_ratio / 0.05
                elif face_ratio > 0.5:  # é¡”ãŒå¤§ãã™ãã‚‹
                    face_size_normalized = max(0.0, 1.0 - (face_ratio - 0.5) / 0.5)
                
                # ç·åˆå“è³ªã‚¹ã‚³ã‚¢è¨ˆç®—
                quality_score = (
                    blur_normalized * 0.4 +      # ãƒ–ãƒ¬ãŒæœ€é‡è¦
                    brightness_normalized * 0.3 + # æ˜ã‚‹ã•é‡è¦
                    face_size_normalized * 0.3    # é¡”ã‚µã‚¤ã‚ºé‡è¦
                )
                
                # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ï¼ˆè©³ç´°ç‰ˆã¯ä¸€éƒ¨ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã¿è¡¨ç¤ºï¼‰
                if frame_count % 50 == 0:
                    print(f"ãƒ•ãƒ¬ãƒ¼ãƒ  {frame_count}: ãƒ–ãƒ¬={blur_score:.1f}, æ˜ã‚‹ã•={brightness_score:.1f}, "
                          f"é¡”æ¯”ç‡={face_ratio:.3f}, å“è³ª={quality_score:.3f}")
            
            # è©•ä¾¡çµæœã‚’ä¿å­˜
            frame_evaluations.append({
                'frame_number': frame_count,
                'timestamp': frame_count / fps if fps > 0 else 0,
                'quality_score': quality_score,
                'blur_score': blur_score,
                'brightness_score': brightness_score,
                'has_face': has_face,
                'face_ratio': face_ratio,
                'face_bbox': face_bbox,
                'frame': frame.copy()  # ãƒ•ãƒ¬ãƒ¼ãƒ ç”»åƒã‚‚ä¿å­˜
            })
        
        frame_count += 1
        
        # é€²æ—è¡¨ç¤º
        if frame_count % 100 == 0:
            progress = (frame_count / total_frames) * 100
            print(f"å‡¦ç†é€²æ—: {progress:.1f}% ({frame_count}/{total_frames})")
    
    cap.release()
    
    print(f"âœ… {len(frame_evaluations)}ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è©•ä¾¡ã—ã¾ã—ãŸ")
    
    # å“è³ªã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆï¼ˆé«˜ã„é †ï¼‰
    frame_evaluations.sort(key=lambda x: x['quality_score'], reverse=True)
    
    # ä¸Šä½ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’é¸æŠï¼ˆæ™‚é–“çš„ã«åˆ†æ•£ã•ã›ã‚‹ï¼‰
    selected_frames = []
    selected_timestamps = []
    min_time_gap = duration / (target_count * 2)  # æœ€å°æ™‚é–“é–“éš”
    
    for eval_data in frame_evaluations:
        if len(selected_frames) >= target_count:
            break
        
        timestamp = eval_data['timestamp']
        
        # æ—¢é¸æŠãƒ•ãƒ¬ãƒ¼ãƒ ã¨æ™‚é–“çš„ã«ååˆ†é›¢ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        too_close = False
        for selected_time in selected_timestamps:
            if abs(timestamp - selected_time) < min_time_gap:
                too_close = True
                break
        
        if not too_close and eval_data['quality_score'] > 0.3:  # æœ€ä½å“è³ªé–¾å€¤
            selected_frames.append(eval_data)
            selected_timestamps.append(timestamp)
    
    # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
    saved_paths = []
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    for i, eval_data in enumerate(selected_frames):
        filename = f"{person_id}_{timestamp}_frame_{i+1}_q{eval_data['quality_score']:.2f}.jpg"
        filepath = frames_dir / filename
        
        cv2.imwrite(str(filepath), eval_data['frame'])
        saved_paths.append(str(filepath))
        
        print(f"âœ… ä¿å­˜: {filename} (å“è³ª: {eval_data['quality_score']:.3f}, "
              f"æ™‚åˆ»: {eval_data['timestamp']:.1f}s)")
    
    # è©•ä¾¡çµ±è¨ˆã‚’è¡¨ç¤º
    if frame_evaluations:
        all_scores = [e['quality_score'] for e in frame_evaluations]
        selected_scores = [e['quality_score'] for e in selected_frames]
        
        print(f"\nğŸ“ˆ è©•ä¾¡çµ±è¨ˆ:")
        print(f"å…¨ãƒ•ãƒ¬ãƒ¼ãƒ å“è³ª: æœ€å¤§={max(all_scores):.3f}, å¹³å‡={np.mean(all_scores):.3f}, æœ€å°={min(all_scores):.3f}")
        if selected_scores:
            print(f"é¸æŠãƒ•ãƒ¬ãƒ¼ãƒ å“è³ª: æœ€å¤§={max(selected_scores):.3f}, å¹³å‡={np.mean(selected_scores):.3f}, æœ€å°={min(selected_scores):.3f}")
        print(f"é¸æŠãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {len(selected_frames)}/{target_count}")
    
    return saved_paths

def register_person_with_video():
    """å‹•ç”»æ’®å½±ã«ã‚ˆã‚‹äººç‰©ç™»éŒ²"""
    print("\n" + "="*60)
    print(" å‹•ç”»æ’®å½±ã«ã‚ˆã‚‹äººç‰©ç™»éŒ²")
    print("="*60)
    
    # åŸºæœ¬æƒ…å ±å…¥åŠ›
    person_id = input("äººç‰©IDï¼ˆè‹±æ•°å­—ã€ä¾‹ï¼šfamily_dadï¼‰: ").strip()
    if not person_id:
        print("âŒ äººç‰©IDã¯å¿…é ˆã§ã™")
        return
    
    if not person_id.replace('_', '').isalnum():
        print("âŒ äººç‰©IDã¯è‹±æ•°å­—ã¨ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢(_)ã®ã¿ä½¿ç”¨å¯èƒ½ã§ã™")
        return
    
    name = input("åå‰: ").strip()
    if not name:
        print("âŒ åå‰ã¯å¿…é ˆã§ã™")
        return
    
    relationship = input("é–¢ä¿‚æ€§ï¼ˆä¾‹ï¼šå®¶æ—ã€å‹äººã€é…é”å“¡ï¼‰: ").strip()
    notes = input("å‚™è€ƒï¼ˆä¾‹ï¼šã„ã¤ã‚‚ã®éƒµä¾¿å±‹ã•ã‚“ï¼‰: ").strip()
    
    print(f"\nç™»éŒ²æƒ…å ±:")
    print(f"ID: {person_id}")
    print(f"åå‰: {name}")
    print(f"é–¢ä¿‚æ€§: {relationship}")
    print(f"å‚™è€ƒ: {notes}")
    
    confirm = input("\nã“ã®æƒ…å ±ã§ç™»éŒ²ã—ã¾ã™ã‹ï¼Ÿ (y/N): ").lower()
    if confirm not in ['y', 'yes']:
        print("âŒ ç™»éŒ²ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
        return
    
    # æ’®å½±è¨­å®š
    print("\nğŸ“¹ å‹•ç”»æ’®å½±è¨­å®š:")
    duration_input = input("æ’®å½±æ™‚é–“ï¼ˆç§’ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ10ç§’ï¼‰: ").strip()
    try:
        duration = int(duration_input) if duration_input else 10
        duration = max(5, min(60, duration))  # 5-60ç§’ã®ç¯„å›²
    except ValueError:
        duration = 10
    
    frame_count_input = input("æŠ½å‡ºãƒ•ãƒ¬ãƒ¼ãƒ æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ5æšï¼‰: ").strip()
    try:
        frame_count = int(frame_count_input) if frame_count_input else 5
        frame_count = max(3, min(20, frame_count))  # 3-20æšã®ç¯„å›²
    except ValueError:
        frame_count = 5
    
    print(f"\nè¨­å®š: {duration}ç§’æ’®å½±, {frame_count}æšæŠ½å‡º")
    
    # å‹•ç”»æ’®å½±
    print("\nğŸ“¸ å‹•ç”»æ’®å½±ã‚’é–‹å§‹ã—ã¾ã™...")
    print("æ³¨æ„: ä»–ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã‚«ãƒ¡ãƒ©ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹å ´åˆã¯å…ˆã«çµ‚äº†ã—ã¦ãã ã•ã„")
    
    ready = input("æº–å‚™ãŒã§ããŸã‚‰Enterã‚­ãƒ¼ã‚’æŠ¼ã—ã¦ãã ã•ã„...")
    
    video_path = record_video_for_registration(person_id, name, duration)
    
    if not video_path:
        print("âŒ å‹•ç”»æ’®å½±ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return
    
    print(f"âœ… å‹•ç”»æ’®å½±å®Œäº†: {Path(video_path).name}")
    
    # ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡º
    photo_paths = extract_best_frames_from_video(video_path, person_id, frame_count)
    
    if not photo_paths:
        print("âŒ ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ")
        return
    
    print(f"âœ… {len(photo_paths)}æšã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æŠ½å‡ºã—ã¾ã—ãŸ")
    
    # é¡”èªè­˜ã‚·ã‚¹ãƒ†ãƒ ã§ç™»éŒ²
    try:
        from face_recognition_advanced import AdvancedFaceRecognizer
        recognizer = AdvancedFaceRecognizer()
        
        if not recognizer.is_available():
            print("âŒ face_recognition ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            print("ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: pip install face-recognition")
            return
        
        print(f"\nğŸ“Š {len(photo_paths)}æšã®ç”»åƒã‹ã‚‰é¡”ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’æŠ½å‡ºä¸­...")
        
        success = recognizer.register_person(
            person_id=person_id,
            name=name,
            image_paths=photo_paths,
            relationship=relationship,
            notes=notes
        )
        
        if success:
            print(f"ğŸ‰ {name}ã•ã‚“ã®ç™»éŒ²ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
            print(f"äººç‰©ID: {person_id}")
            print(f"ç™»éŒ²ç”»åƒæ•°: {len(photo_paths)}æš")
            print(f"é–¢ä¿‚æ€§: {relationship}")
            print(f"å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«: {Path(video_path).name}")
            
            # å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã™ã‚‹ã‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ç¢ºèª
            delete_video = input("\nå…ƒã®å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã™ã‹ï¼Ÿ (Y/n): ").lower()
            if delete_video in ['', 'y', 'yes']:
                try:
                    Path(video_path).unlink()
                    print("âœ… å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
                except Exception as e:
                    print(f"âš  å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")
            
            # ç™»éŒ²ãƒ†ã‚¹ãƒˆ
            test_choice = input("\nç™»éŒ²ã—ãŸäººç‰©ã®èªè­˜ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã¾ã™ã‹ï¼Ÿ (y/N): ").lower()
            if test_choice in ['y', 'yes']:
                test_recognition_for_person(person_id, name)
                
        else:
            print("âŒ ç™»éŒ²ã«å¤±æ•—ã—ã¾ã—ãŸ")
            print("æŠ½å‡ºã—ãŸãƒ•ãƒ¬ãƒ¼ãƒ ã«é¡”ãŒæ˜ç¢ºã«å†™ã£ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„")
            
    except ImportError:
        print("âŒ face_recognition ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        print("ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ–¹æ³•:")
        print("1. pip install face-recognition")
        print("2. ã¾ãŸã¯: python advanced_face_setup.py")
        
    except Exception as e:
        print(f"âŒ ç™»éŒ²ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")


def take_photo_for_registration(person_id: str, name: str, count: int = 3) -> list:
    """ç™»éŒ²ç”¨ã®å†™çœŸã‚’æ’®å½±ï¼ˆä¿®æ­£ç‰ˆï¼‰"""
    print(f"\n{name}ã•ã‚“ã®å†™çœŸã‚’{count}æšæ’®å½±ã—ã¾ã™ã€‚")
    print("ã‚«ãƒ¡ãƒ©ã®å‰ã«åº§ã£ã¦ã€ä»¥ä¸‹ã®ãƒãƒ¼ã‚ºã‚’ã¨ã£ã¦ãã ã•ã„ï¼š")
    print("1. æ­£é¢ã‚’å‘ã„ã¦")
    print("2. å°‘ã—å·¦ã‚’å‘ã„ã¦")
    print("3. å°‘ã—å³ã‚’å‘ã„ã¦")
    print("\næ“ä½œæ–¹æ³•:")
    print("- ã‚¹ãƒšãƒ¼ã‚¹ã‚­ãƒ¼: æ’®å½±")
    print("- Escã‚­ãƒ¼: ã‚­ãƒ£ãƒ³ã‚»ãƒ«")
    print("- qã‚­ãƒ¼: çµ‚äº†")
    
    photos_dir = config.DATA_DIR / "registration_photos" / person_id
    photos_dir.mkdir(parents=True, exist_ok=True)
    
    # ã‚«ãƒ¡ãƒ©åˆæœŸåŒ–ï¼ˆWindowså¯¾å¿œï¼‰
    camera = cv2.VideoCapture(0, cv2.CAP_DSHOW)  # DirectShowä½¿ç”¨
    
    if not camera.isOpened():
        print("âŒ ã‚«ãƒ¡ãƒ©ã‚’é–‹ã‘ã¾ã›ã‚“ã§ã—ãŸ")
        print("ä»–ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒã‚«ãƒ¡ãƒ©ã‚’ä½¿ç”¨ã—ã¦ã„ãªã„ã‹ç¢ºèªã—ã¦ãã ã•ã„")
        return []
    
    # ã‚«ãƒ¡ãƒ©è¨­å®š
    camera.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    camera.set(cv2.CAP_PROP_FPS, 30)
    
    photo_paths = []
    current_photo = 0
    
    print(f"\nğŸ“¸ ã‚«ãƒ¡ãƒ©ã‚’èµ·å‹•ã—ã¾ã—ãŸã€‚å†™çœŸ {current_photo + 1}/{count} ã®æº–å‚™ã‚’ã—ã¦ãã ã•ã„...")
    
    # å°‘ã—å¾…æ©Ÿã—ã¦ã‚«ãƒ¡ãƒ©ã‚’å®‰å®šåŒ–
    time.sleep(2)
    
    try:
        while current_photo < count:
            ret, frame = camera.read()
            if not ret:
                print("âŒ ãƒ•ãƒ¬ãƒ¼ãƒ ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
                break
            
            # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å·¦å³åè»¢ï¼ˆé¡åƒè¡¨ç¤ºï¼‰
            frame = cv2.flip(frame, 1)
            
            # æ’®å½±ã‚¬ã‚¤ãƒ‰è¡¨ç¤º
            cv2.putText(frame, f"Photo {current_photo + 1}/{count}", 
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            cv2.putText(frame, f"Person: {name}", 
                       (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
            
            # æ“ä½œèª¬æ˜
            cv2.putText(frame, "SPACE: Take Photo, ESC: Cancel, Q: Quit", 
                       (10, frame.shape[0] - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
            
            # æ’®å½±ãƒãƒ¼ã‚ºã®ã‚¬ã‚¤ãƒ‰
            pose_guides = ["Face forward", "Turn slightly left", "Turn slightly right"]
            if current_photo < len(pose_guides):
                cv2.putText(frame, pose_guides[current_photo], 
                           (10, 110), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
            
            # ä¸­å¤®ã«æ’®å½±æ ã‚’è¡¨ç¤º
            h, w = frame.shape[:2]
            cv2.rectangle(frame, (w//4, h//4), (3*w//4, 3*h//4), (0, 255, 0), 2)
            cv2.putText(frame, "Face area", (w//4, h//4 - 10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            
            cv2.imshow(f'Registration - {name}', frame)
            
            # ã‚­ãƒ¼å…¥åŠ›å‡¦ç†ï¼ˆä¿®æ­£ç‰ˆï¼‰
            key = cv2.waitKey(1) & 0xFF
            
            if key == ord(' '):  # ã‚¹ãƒšãƒ¼ã‚¹ã‚­ãƒ¼
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                photo_path = photos_dir / f"{person_id}_{timestamp}_{current_photo + 1}.jpg"
                
                # æ’®å½±æ™‚ã¯åè»¢ã—ãªã„å…ƒã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä¿å­˜
                original_frame = cv2.flip(frame, 1)  # 2å›åè»¢ã§å…ƒã«æˆ»ã™
                cv2.imwrite(str(photo_path), original_frame)
                photo_paths.append(str(photo_path))
                
                print(f"âœ… æ’®å½±å®Œäº† {current_photo + 1}/{count}: {photo_path.name}")
                current_photo += 1
                
                if current_photo < count:
                    print(f"ğŸ“¸ æ¬¡ã®å†™çœŸ {current_photo + 1}/{count} ã®æº–å‚™ã‚’ã—ã¦ãã ã•ã„...")
                
                # æ’®å½±å¾Œå°‘ã—å¾…æ©Ÿ
                time.sleep(1)
                
            elif key == 27:  # Escapeã‚­ãƒ¼
                print("âŒ æ’®å½±ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
                break
                
            elif key == ord('q') or key == ord('Q'):  # qã‚­ãƒ¼
                print("âŒ æ’®å½±ã‚’çµ‚äº†ã—ã¾ã—ãŸ")
                break
    
    except KeyboardInterrupt:
        print("âŒ æ’®å½±ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
    
    finally:
        camera.release()
        cv2.destroyAllWindows()
        print(f"ğŸ“· ã‚«ãƒ¡ãƒ©ã‚’åœæ­¢ã—ã¾ã—ãŸ")
    
    if current_photo == count:
        print(f"ğŸ‰ {count}æšã®å†™çœŸæ’®å½±ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    else:
        print(f"âš  {current_photo}æšã®å†™çœŸã®ã¿æ’®å½±ã•ã‚Œã¾ã—ãŸ")
    
    return photo_paths

def register_person_interactive():
    """å¯¾è©±å¼ã§äººç‰©ã‚’ç™»éŒ²ï¼ˆä¿®æ­£ç‰ˆï¼‰"""
    print("\n" + "="*60)
    print(" æ–°ã—ã„äººç‰©ã®ç™»éŒ²")
    print("="*60)
    
    # åŸºæœ¬æƒ…å ±å…¥åŠ›
    person_id = input("äººç‰©IDï¼ˆè‹±æ•°å­—ã€ä¾‹ï¼šfamily_dadï¼‰: ").strip()
    if not person_id:
        print("âŒ äººç‰©IDã¯å¿…é ˆã§ã™")
        return
    
    # è‹±æ•°å­—ã¨ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã®ã¿è¨±å¯
    if not person_id.replace('_', '').isalnum():
        print("âŒ äººç‰©IDã¯è‹±æ•°å­—ã¨ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢(_)ã®ã¿ä½¿ç”¨å¯èƒ½ã§ã™")
        return
    
    name = input("åå‰: ").strip()
    if not name:
        print("âŒ åå‰ã¯å¿…é ˆã§ã™")
        return
    
    relationship = input("é–¢ä¿‚æ€§ï¼ˆä¾‹ï¼šå®¶æ—ã€å‹äººã€é…é”å“¡ï¼‰: ").strip()
    notes = input("å‚™è€ƒï¼ˆä¾‹ï¼šã„ã¤ã‚‚ã®éƒµä¾¿å±‹ã•ã‚“ï¼‰: ").strip()
    
    print(f"\nç™»éŒ²æƒ…å ±:")
    print(f"ID: {person_id}")
    print(f"åå‰: {name}")
    print(f"é–¢ä¿‚æ€§: {relationship}")
    print(f"å‚™è€ƒ: {notes}")
    
    confirm = input("\nã“ã®æƒ…å ±ã§ç™»éŒ²ã—ã¾ã™ã‹ï¼Ÿ (y/N): ").lower()
    if confirm not in ['y', 'yes']:
        print("âŒ ç™»éŒ²ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
        return
    
    # å†™çœŸæ’®å½±æ–¹æ³•é¸æŠ
    print("\nå†™çœŸã®è¿½åŠ æ–¹æ³•ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼š")
    print("1. ã‚«ãƒ¡ãƒ©ã§æ’®å½±")
    print("2. æ—¢å­˜ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®š")
    print("3. ã‚¹ã‚­ãƒƒãƒ—ï¼ˆå¾Œã§è¿½åŠ ï¼‰")
    
    choice = input("é¸æŠ (1/2/3): ").strip()
    
    photo_paths = []
    
    if choice == "1":
        # ã‚«ãƒ¡ãƒ©ã§æ’®å½±
        print("\nğŸ“¸ ã‚«ãƒ¡ãƒ©ã§ã®æ’®å½±ã‚’é–‹å§‹ã—ã¾ã™...")
        print("æ³¨æ„: ä»–ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã‚«ãƒ¡ãƒ©ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹å ´åˆã¯å…ˆã«çµ‚äº†ã—ã¦ãã ã•ã„")
        
        ready = input("æº–å‚™ãŒã§ããŸã‚‰Enterã‚­ãƒ¼ã‚’æŠ¼ã—ã¦ãã ã•ã„...")
        photo_paths = take_photo_for_registration(person_id, name, 3)
        
    elif choice == "2":
        # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®š
        print("ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆè¤‡æ•°å¯ã€ç©ºè¡Œã§çµ‚äº†ï¼‰:")
        while True:
            path = input("ç”»åƒãƒ‘ã‚¹: ").strip()
            if not path:
                break
            if Path(path).exists():
                photo_paths.append(path)
                print(f"âœ… è¿½åŠ : {path}")
            else:
                print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {path}")
                
    elif choice == "3":
        print("âš  å†™çœŸãªã—ã§ç™»éŒ²ã—ã¾ã™ï¼ˆå¾Œã§è¿½åŠ ã—ã¦ãã ã•ã„ï¼‰")
        
    else:
        print("âŒ ç„¡åŠ¹ãªé¸æŠã§ã™")
        return
    
    # é¡”èªè­˜ã‚·ã‚¹ãƒ†ãƒ ã§ç™»éŒ²ï¼ˆå†™çœŸãŒã‚ã‚‹å ´åˆã®ã¿ï¼‰
    if photo_paths:
        try:
            # face_recognitionãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ãƒ†ã‚¹ãƒˆ
            import face_recognition
            print("âœ… face_recognition ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨å¯èƒ½ã§ã™")
            
            from face_recognition_advanced import AdvancedFaceRecognizer
            recognizer = AdvancedFaceRecognizer()
            
            if not recognizer.is_available():
                print("âŒ face_recognition ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
                print("ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: pip install face-recognition")
                return
            
            print(f"\nğŸ“Š {len(photo_paths)}æšã®ç”»åƒã‹ã‚‰é¡”ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’æŠ½å‡ºä¸­...")
            
            success = recognizer.register_person(
                person_id=person_id,
                name=name,
                image_paths=photo_paths,
                relationship=relationship,
                notes=notes
            )
            
            if success:
                print(f"ğŸ‰ {name}ã•ã‚“ã®ç™»éŒ²ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                print(f"äººç‰©ID: {person_id}")
                print(f"ç™»éŒ²ç”»åƒæ•°: {len(photo_paths)}æš")
                print(f"é–¢ä¿‚æ€§: {relationship}")
                
                # ç™»éŒ²ãƒ†ã‚¹ãƒˆ
                test_choice = input("\nç™»éŒ²ã—ãŸäººç‰©ã®èªè­˜ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã¾ã™ã‹ï¼Ÿ (y/N): ").lower()
                if test_choice in ['y', 'yes']:
                    test_recognition_for_person(person_id, name)
                
            else:
                print("âŒ ç™»éŒ²ã«å¤±æ•—ã—ã¾ã—ãŸ")
                print("å†™çœŸã«é¡”ãŒæ˜ç¢ºã«å†™ã£ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„")
                
        except ImportError:
            print("âŒ face_recognition ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            print("ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ–¹æ³•:")
            print("1. pip install face-recognition")
            print("2. ã¾ãŸã¯: python setup_advanced_face.py")
            
        except Exception as e:
            print(f"âŒ ç™»éŒ²ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    else:
        print("âš  å†™çœŸãŒç™»éŒ²ã•ã‚Œã¦ã„ãªã„ãŸã‚ã€é¡”èªè­˜æ©Ÿèƒ½ã¯ä½¿ç”¨ã§ãã¾ã›ã‚“")
        print("å¾Œã§å†™çœŸã‚’è¿½åŠ ã—ã¦ãã ã•ã„: python face_manager.py register")

def test_recognition_for_person(person_id: str, name: str):
    """ç‰¹å®šã®äººç‰©ã®èªè­˜ãƒ†ã‚¹ãƒˆ"""
    print(f"\nğŸ” {name}ã•ã‚“ã®èªè­˜ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹ã—ã¾ã™...")
    print("ã‚«ãƒ¡ãƒ©ã®å‰ã«åº§ã£ã¦ãã ã•ã„ï¼ˆEscã‚­ãƒ¼ã§çµ‚äº†ï¼‰")
    
    try:
        from face_recognition_advanced import AdvancedFaceRecognizer
        from models import CameraFrame
        
        recognizer = AdvancedFaceRecognizer()
        
        # ã‚«ãƒ¡ãƒ©åˆæœŸåŒ–
        camera = cv2.VideoCapture(0, cv2.CAP_DSHOW)
        if not camera.isOpened():
            print("âŒ ã‚«ãƒ¡ãƒ©ã‚’é–‹ã‘ã¾ã›ã‚“ã§ã—ãŸ")
            return
        
        print("âœ… èªè­˜ãƒ†ã‚¹ãƒˆé–‹å§‹ - Escã‚­ãƒ¼ã§çµ‚äº†")
        
        while True:
            ret, frame = camera.read()
            if not ret:
                continue
            
            # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å·¦å³åè»¢
            frame = cv2.flip(frame, 1)
            
            # CameraFrameã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
            camera_frame = CameraFrame(
                image=frame,
                timestamp=datetime.now(),
                width=frame.shape[1],
                height=frame.shape[0],
                source="test_camera"
            )
            
            # é¡”èªè­˜å®Ÿè¡Œ
            result = recognizer.recognize_person(camera_frame)
            
            # çµæœã‚’ç”»åƒã«æç”»
            if result.face_detections:
                annotated_frame = recognizer.draw_detections(camera_frame, result.face_detections)
            else:
                annotated_frame = frame
            
            # çµæœè¡¨ç¤º
            if result.is_known_person and result.person_id == person_id:
                cv2.putText(annotated_frame, f"RECOGNIZED: {name}", 
                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                cv2.putText(annotated_frame, f"Confidence: {result.confidence:.2f}", 
                           (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
                cv2.putText(annotated_frame, "SUCCESS!", 
                           (10, 110), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
            elif result.is_known_person:
                other_info = recognizer.get_person_info(result.person_id)
                other_name = other_info['name'] if other_info else result.person_id
                cv2.putText(annotated_frame, f"WRONG PERSON: {other_name}", 
                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
            else:
                cv2.putText(annotated_frame, "NOT RECOGNIZED", 
                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
                if result.face_detections:
                    cv2.putText(annotated_frame, "Face detected but unknown", 
                               (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)
                else:
                    cv2.putText(annotated_frame, "No face detected", 
                               (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)
            
            cv2.putText(annotated_frame, "Press ESC to exit", 
                       (10, annotated_frame.shape[0] - 10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            
            cv2.imshow(f'Recognition Test - {name}', annotated_frame)
            
            key = cv2.waitKey(1) & 0xFF
            if key == 27:  # Escapeã‚­ãƒ¼
                break
        
        camera.release()
        cv2.destroyAllWindows()
        print("âœ… èªè­˜ãƒ†ã‚¹ãƒˆçµ‚äº†")
        
    except ImportError:
        print("âŒ å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
    except Exception as e:
        print(f"âŒ èªè­˜ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")

def list_registered_persons():
    """ç™»éŒ²æ¸ˆã¿äººç‰©ä¸€è¦§è¡¨ç¤º"""
    try:
        from face_recognition_advanced import AdvancedFaceRecognizer
        recognizer = AdvancedFaceRecognizer()
        
        if not recognizer.is_available():
            print("âŒ face_recognition ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return
        
        persons = recognizer.get_all_persons()
        
        if not persons:
            print("ğŸ“ ç™»éŒ²ã•ã‚ŒãŸäººç‰©ã¯ã„ã¾ã›ã‚“")
            return
        
        print("\n" + "="*80)
        print(" ç™»éŒ²æ¸ˆã¿äººç‰©ä¸€è¦§")
        print("="*80)
        print(f"{'ID':<15} {'åå‰':<15} {'é–¢ä¿‚æ€§':<10} {'èªè­˜å›æ•°':<8} {'æœ€çµ‚ç¢ºèª':<12}")
        print("-"*80)
        
        for person in persons:
            last_seen = person['last_seen']
            if last_seen:
                last_seen = datetime.fromisoformat(last_seen).strftime('%m/%d %H:%M')
            else:
                last_seen = "æœªèªè­˜"
            
            print(f"{person['person_id']:<15} {person['name']:<15} {person['relationship']:<10} "
                  f"{person['recognition_count']:<8} {last_seen:<12}")
        
        print(f"\nåˆè¨ˆ: {len(persons)}äººãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã™")
        
    except ImportError:
        print("âŒ face_recognition ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")

def delete_person_interactive():
    """å¯¾è©±å¼ã§äººç‰©ã‚’å‰Šé™¤"""
    try:
        from face_recognition_advanced import AdvancedFaceRecognizer
        recognizer = AdvancedFaceRecognizer()
        
        if not recognizer.is_available():
            print("âŒ face_recognition ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return
        
        # ç™»éŒ²æ¸ˆã¿äººç‰©ä¸€è¦§è¡¨ç¤º
        list_registered_persons()
        
        print("\nå‰Šé™¤ã—ãŸã„äººç‰©ã®IDã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:")
        person_id = input("äººç‰©ID: ").strip()
        
        if not person_id:
            print("âŒ IDãŒå…¥åŠ›ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
            return
        
        # äººç‰©æƒ…å ±ç¢ºèª
        person_info = recognizer.get_person_info(person_id)
        if not person_info:
            print(f"âŒ äººç‰©ID '{person_id}' ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return
        
        print(f"\nå‰Šé™¤å¯¾è±¡:")
        print(f"ID: {person_info['person_id']}")
        print(f"åå‰: {person_info['name']}")
        print(f"é–¢ä¿‚æ€§: {person_info['relationship']}")
        print(f"èªè­˜å›æ•°: {person_info['recognition_count']}")
        
        confirm = input(f"\n'{person_info['name']}'ã•ã‚“ã‚’å‰Šé™¤ã—ã¾ã™ã‹ï¼Ÿ (y/N): ").lower()
        if confirm not in ['y', 'yes']:
            print("âŒ å‰Šé™¤ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
            return
        
        if recognizer.delete_person(person_id):
            print(f"âœ… {person_info['name']}ã•ã‚“ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
        else:
            print("âŒ å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸ")
            
    except ImportError:
        print("âŒ face_recognition ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")

def show_recognition_stats():
    """èªè­˜çµ±è¨ˆè¡¨ç¤º"""
    try:
        from face_recognition_advanced import AdvancedFaceRecognizer
        recognizer = AdvancedFaceRecognizer()
        
        if not recognizer.is_available():
            print("âŒ face_recognition ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return
        
        stats = recognizer.get_recognition_stats()
        
        print("\n" + "="*60)
        print(" èªè­˜çµ±è¨ˆ")
        print("="*60)
        print(f"ç™»éŒ²äººæ•°: {stats.get('total_persons', 0)}äºº")
        print(f"ç·èªè­˜å›æ•°: {stats.get('total_recognitions', 0)}å›")
        print(f"ä»Šæ—¥ã®èªè­˜å›æ•°: {stats.get('today_recognitions', 0)}å›")
        print(f"ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ•°: {stats.get('encodings_count', 0)}å€‹")
        print(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹: {stats.get('database_path', 'N/A')}")
        
    except ImportError:
        print("âŒ face_recognition ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")

def test_recognition_system():
    """èªè­˜ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆï¼ˆä¿®æ­£ç‰ˆï¼‰"""
    print("\n" + "="*60)
    print(" èªè­˜ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ")
    print("="*60)
    
    try:
        from face_recognition_advanced import AdvancedFaceRecognizer
        recognizer = AdvancedFaceRecognizer()
        
        if not recognizer.is_available():
            print("âŒ face_recognition ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            print("ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: pip install face-recognition")
            return
        
        print("ğŸ“¸ ã‚«ãƒ¡ãƒ©ã§èªè­˜ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹ã—ã¾ã™")
        print("æ“ä½œæ–¹æ³•: Escã‚­ãƒ¼=çµ‚äº†, Qã‚­ãƒ¼=çµ‚äº†")
        
        # ã‚«ãƒ¡ãƒ©åˆæœŸåŒ–
        camera = cv2.VideoCapture(0, cv2.CAP_DSHOW)
        if not camera.isOpened():
            print("âŒ ã‚«ãƒ¡ãƒ©ã‚’é–‹ã‘ã¾ã›ã‚“ã§ã—ãŸ")
            return
        
        # ã‚«ãƒ¡ãƒ©è¨­å®š
        camera.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        
        print("âœ… ã‚«ãƒ¡ãƒ©é–‹å§‹ - é¡”èªè­˜ãƒ†ã‚¹ãƒˆä¸­...")
        
        from models import CameraFrame
        
        while True:
            ret, frame = camera.read()
            if not ret:
                continue
            
            # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å·¦å³åè»¢
            frame = cv2.flip(frame, 1)
            
            # CameraFrameã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
            camera_frame = CameraFrame(
                image=frame,
                timestamp=datetime.now(),
                width=frame.shape[1],
                height=frame.shape[0],
                source="test_camera"
            )
            
            # é¡”èªè­˜å®Ÿè¡Œ
            result = recognizer.recognize_person(camera_frame)
            
            # çµæœã‚’ç”»åƒã«æç”»
            if result.face_detections:
                annotated_frame = recognizer.draw_detections(camera_frame, result.face_detections)
            else:
                annotated_frame = frame
            
            # çµæœè¡¨ç¤º
            if result.is_known_person:
                person_info = recognizer.get_person_info(result.person_id)
                name = person_info['name'] if person_info else result.person_id
                relationship = person_info.get('relationship', '') if person_info else ''
                
                cv2.putText(annotated_frame, f"Recognized: {name}", 
                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                cv2.putText(annotated_frame, f"Relationship: {relationship}", 
                           (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                cv2.putText(annotated_frame, f"Confidence: {result.confidence:.2f}", 
                           (10, 110), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            else:
                if result.face_detections:
                    cv2.putText(annotated_frame, "Unknown Person", 
                               (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
                    cv2.putText(annotated_frame, f"Faces detected: {len(result.face_detections)}", 
                               (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
                else:
                    cv2.putText(annotated_frame, "No Face Detected", 
                               (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)
            
            cv2.putText(annotated_frame, "Press ESC or Q to exit", 
                       (10, annotated_frame.shape[0] - 10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            
            cv2.imshow('Face Recognition Test', annotated_frame)
            
            key = cv2.waitKey(1) & 0xFF
            if key == 27 or key == ord('q') or key == ord('Q'):  # Escape or Q
                break
        
        camera.release()
        cv2.destroyAllWindows()
        print("âœ… èªè­˜ãƒ†ã‚¹ãƒˆçµ‚äº†")
        
    except ImportError:
        print("âŒ å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        print("ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: python setup_advanced_face.py")
    except Exception as e:
        print(f"âŒ èªè­˜ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")

def export_database():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’JSONã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
    try:
        from face_recognition_advanced import AdvancedFaceRecognizer
        recognizer = AdvancedFaceRecognizer()
        
        if not recognizer.is_available():
            print("âŒ face_recognition ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return
        
        persons = recognizer.get_all_persons()
        stats = recognizer.get_recognition_stats()
        
        export_data = {
            'export_date': datetime.now().isoformat(),
            'statistics': stats,
            'persons': persons
        }
        
        export_file = config.DATA_DIR / f"face_database_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        with open(export_file, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ã¾ã—ãŸ: {export_file}")
        
    except ImportError:
        print("âŒ face_recognition ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")

def setup_sample_persons():
    """ã‚µãƒ³ãƒ—ãƒ«äººç‰©ãƒ‡ãƒ¼ã‚¿ã®èª¬æ˜"""
    print("\n" + "="*60)
    print(" ã‚µãƒ³ãƒ—ãƒ«äººç‰©ãƒ‡ãƒ¼ã‚¿è¨­å®šã‚¬ã‚¤ãƒ‰")
    print("="*60)
    
    sample_persons = [
        {
            'person_id': 'family_dad',
            'name': 'ãŠçˆ¶ã•ã‚“',
            'relationship': 'å®¶æ—',
            'notes': 'ãŠç–²ã‚Œæ§˜ã§ã™'
        },
        {
            'person_id': 'family_mom',
            'name': 'ãŠæ¯ã•ã‚“',
            'relationship': 'å®¶æ—',
            'notes': 'ãŠã‹ãˆã‚Šãªã•ã„'
        },
        {
            'person_id': 'delivery_yamato',
            'name': 'ãƒ¤ãƒãƒˆé…é”å“¡',
            'relationship': 'é…é”å“¡',
            'notes': 'ã„ã¤ã‚‚ã®ãƒ¤ãƒãƒˆé‹è¼¸ã®æ–¹'
        },
        {
            'person_id': 'postman_regular',
            'name': 'éƒµä¾¿é…é”å“¡',
            'relationship': 'éƒµä¾¿å±€å“¡',
            'notes': 'æ¯æ—¥æ¥ã‚‹éƒµä¾¿å±‹ã•ã‚“'
        }
    ]
    
    print("æ¨å¥¨ã™ã‚‹äººç‰©ç™»éŒ²ä¾‹:")
    for i, person in enumerate(sample_persons, 1):
        print(f"\n{i}. {person['name']}")
        print(f"   ID: {person['person_id']}")
        print(f"   é–¢ä¿‚æ€§: {person['relationship']}")
        print(f"   å‚™è€ƒ: {person['notes']}")
    
    print(f"\nç™»éŒ²æ–¹æ³•:")
    print("python face_manager.py register")
    print("\nå„äººç‰©ã®å†™çœŸã‚’3æšãšã¤æ’®å½±ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚")

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(
        description="é¡”èªè­˜ç®¡ç†ãƒ„ãƒ¼ãƒ«ï¼ˆå‹•ç”»æ’®å½±å¯¾å¿œç‰ˆï¼‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  python face_manager.py register         # é™æ­¢ç”»æ’®å½±ã§ç™»éŒ²
  python face_manager.py register_video   # å‹•ç”»æ’®å½±ã§ç™»éŒ²ï¼ˆæ¨å¥¨ï¼‰
  python face_manager.py list            # ç™»éŒ²æ¸ˆã¿äººç‰©ä¸€è¦§
  python face_manager.py delete          # äººç‰©ã‚’å‰Šé™¤
  python face_manager.py test            # èªè­˜ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ
  python face_manager.py stats           # èªè­˜çµ±è¨ˆè¡¨ç¤º
  python face_manager.py export          # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
  python face_manager.py sample_guide    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿è¨­å®šã‚¬ã‚¤ãƒ‰
"""
    )

    parser.add_argument(
        "command",
        choices=["register", "register_video", "list", "delete", "test", "stats", "export", "sample_guide"],
        help="å®Ÿè¡Œã™ã‚‹ã‚³ãƒãƒ³ãƒ‰"
    )

    args = parser.parse_args()

    if args.command == "register":
        # å¾“æ¥ã®é™æ­¢ç”»æ’®å½±
        from face_manager import register_person_interactive
        register_person_interactive()
    elif args.command == "register_video":
        # æ–°ã—ã„å‹•ç”»æ’®å½±
        register_person_with_video()
    elif args.command == "list":
        list_registered_persons()
    elif args.command == "delete":
        delete_person_interactive()
    elif args.command == "test":
        test_recognition_system()
    elif args.command == "stats":
        show_recognition_stats()
    elif args.command == "export":
        export_database()
    elif args.command == "sample_guide":
        setup_sample_persons()
    else:
        parser.print_help()

if __name__ == "__main__":
    main()
"""
è¦–è¦šéšœå®³è€…å‘ã‘ç„é–¢è¨ªå•è€…èªè­˜ã‚·ã‚¹ãƒ†ãƒ  - YOLOçµ±åˆç‰ˆ
"""
import os
import sys
import time
import cv2
import numpy as np
import base64
import json
import logging
import threading
import requests
import collections
from datetime import datetime, timedelta
from flask import Flask, render_template, request, jsonify, Response

# è‡ªä½œãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from face_detector import FaceDetector
    import config
except ImportError as e:
    print(f"ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    FaceDetector = None

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Flaskã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ–
app = Flask(__name__)

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
camera = None
face_detector = None
is_processing = False
last_result = None
frame_buffer = collections.deque(maxlen=30)  # æœ€å¤§30ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆç´„10ç§’é–“ï¼‰ã®ãƒãƒƒãƒ•ã‚¡
current_frame = None
stream_active = True

# è¨­å®š
CONFIG = {
    "use_camera": getattr(config, 'USE_CAMERA', True),
    "camera_id": getattr(config, 'CAMERA_ID', "/dev/video0"),
    "frame_rate": getattr(config, 'FRAME_RATE', 3),
    "api_url": getattr(config, 'API_BASE_URL', "http://localhost:11434/api/chat"),
    "model_name": getattr(config, 'MODEL_NAME', "gemma3:4b"),
    "api_key": getattr(config, 'API_KEY', "dummy-key"),
    "test_images_dir": getattr(config, 'TEST_IMAGES_DIR', "test_images"),
    "time_offset": 0,
    "stream_quality": 75,
    "use_face_detection": getattr(config, 'USE_FACE_DETECTION', True),
    "system_prompt": getattr(config, 'SYSTEM_PROMPT', ""),
}

# ã‚«ãƒ¡ãƒ©ã‚¯ãƒ©ã‚¹
class RealtimeCamera:
    def __init__(self, use_camera=False, camera_id=0, frame_rate=3):
        self.use_camera = use_camera
        self.camera_id = camera_id
        self.frame_rate = frame_rate
        self.camera = None
        self.test_images = []
        self.current_test_index = 0
        self.is_running = False
        self.last_frame_time = 0
        
        # ãƒ†ã‚¹ãƒˆç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ç¢ºèª
        self._ensure_test_images_dir()

    def _ensure_test_images_dir(self):
        """ãƒ†ã‚¹ãƒˆç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ç¢ºèªã¨ä½œæˆ"""
        test_dir = CONFIG["test_images_dir"]
        if not os.path.exists(test_dir):
            os.makedirs(test_dir)
            logger.info(f"ãƒ†ã‚¹ãƒˆç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã—ã¾ã—ãŸ: {test_dir}")
            self._create_sample_images(test_dir)

    def _create_sample_images(self, test_dir):
        """ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚¹ãƒˆç”»åƒã®ä½œæˆ"""
        logger.info("ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚¹ãƒˆç”»åƒã‚’ä½œæˆã—ã¦ã„ã¾ã™...")
        
        # ã‚µãƒ³ãƒ—ãƒ«1: é…é”å“¡
        delivery_img = np.ones((480, 640, 3), dtype=np.uint8) * 255
        cv2.rectangle(delivery_img, (200, 100), (440, 400), (0, 0, 200), -1)
        cv2.circle(delivery_img, (320, 150), 50, (200, 180, 140), -1)
        cv2.putText(delivery_img, "Delivery Person", (220, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)
        cv2.imwrite(os.path.join(test_dir, "sample1.jpg"), delivery_img)
        
        # ã‚µãƒ³ãƒ—ãƒ«2: ãƒ“ã‚¸ãƒã‚¹ãƒ‘ãƒ¼ã‚½ãƒ³
        business_img = np.ones((480, 640, 3), dtype=np.uint8) * 255
        cv2.rectangle(business_img, (200, 100), (440, 400), (50, 50, 50), -1)
        cv2.circle(business_img, (320, 150), 50, (200, 180, 140), -1)
        cv2.putText(business_img, "Business Person", (220, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)
        cv2.imwrite(os.path.join(test_dir, "sample2.jpg"), business_img)
        
        logger.info("ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚¹ãƒˆç”»åƒã‚’ä½œæˆã—ã¾ã—ãŸ")

    def start(self):
        """ã‚«ãƒ¡ãƒ©ã¾ãŸã¯ãƒ†ã‚¹ãƒˆç”»åƒã®èµ·å‹•"""
        if self.use_camera:
            try:
                self.camera = cv2.VideoCapture(self.camera_id, cv2.CAP_V4L2)
                if not self.camera.isOpened():
                    logger.error(f"ã‚«ãƒ¡ãƒ©ã®èµ·å‹•ã«å¤±æ•—ã—ã¾ã—ãŸ: ID {self.camera_id}")
                    return False
                self.is_running = True
                logger.info("ã‚«ãƒ¡ãƒ©ã®èµ·å‹•ã«æˆåŠŸã—ã¾ã—ãŸ")
                
                # ã‚«ãƒ¡ãƒ©ã®è¨­å®š
                self.camera.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
                self.camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
                
                return True
            except Exception as e:
                logger.error(f"ã‚«ãƒ¡ãƒ©ã®èµ·å‹•ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                return False
        else:
            # ãƒ†ã‚¹ãƒˆç”»åƒã®èª­ã¿è¾¼ã¿
            self._load_test_images()
            if not self.test_images:
                logger.error("ãƒ†ã‚¹ãƒˆç”»åƒãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ")
                return False
            self.is_running = True
            logger.info(f"{len(self.test_images)}æšã®ãƒ†ã‚¹ãƒˆç”»åƒã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
            return True

    def _load_test_images(self):
        """ãƒ†ã‚¹ãƒˆç”»åƒã®ãƒ­ãƒ¼ãƒ‰"""
        self.test_images = []
        test_dir = CONFIG["test_images_dir"]
        
        for file in os.listdir(test_dir):
            if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                image_path = os.path.join(test_dir, file)
                image = cv2.imread(image_path)
                if image is not None:
                    self.test_images.append(image)
                    logger.info(f"ãƒ†ã‚¹ãƒˆç”»åƒã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {file}")
        
        # ãƒ†ã‚¹ãƒˆç”»åƒãŒãªã‘ã‚Œã°ã‚µãƒ³ãƒ—ãƒ«ä½œæˆ
        if not self.test_images:
            self._create_sample_images(test_dir)
            # å†åº¦èª­ã¿è¾¼ã¿
            for file in os.listdir(test_dir):
                if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    image_path = os.path.join(test_dir, file)
                    image = cv2.imread(image_path)
                    if image is not None:
                        self.test_images.append(image)

    def get_frame(self):
        """ãƒ•ãƒ¬ãƒ¼ãƒ ã®å–å¾—"""
        if not self.is_running:
            return None
            
        # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆåˆ¶é™
        current_time = time.time()
        elapsed = current_time - self.last_frame_time
        if elapsed < 1.0 / self.frame_rate:
            return None
            
        self.last_frame_time = current_time
            
        if self.use_camera:
            ret, frame = self.camera.read()
            if not ret:
                logger.error("ã‚«ãƒ¡ãƒ©ã‹ã‚‰ã®ãƒ•ãƒ¬ãƒ¼ãƒ å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return None
            
            # ãƒ•ãƒ¬ãƒ¼ãƒ ã«ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’è¿½åŠ 
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            cv2.putText(frame, timestamp, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
            
            return frame
        else:
            if not self.test_images:
                return None
                
            # æ¬¡ã®ãƒ†ã‚¹ãƒˆç”»åƒã‚’å–å¾—ï¼ˆãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
            frame = self.test_images[self.current_test_index].copy()
            self.current_test_index = (self.current_test_index + 1) % len(self.test_images)
            
            # ãƒ•ãƒ¬ãƒ¼ãƒ ã«ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’è¿½åŠ 
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            cv2.putText(frame, timestamp, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
            
            return frame

    def stop(self):
        """ã‚«ãƒ¡ãƒ©ã®åœæ­¢"""
        if self.use_camera and self.camera:
            self.camera.release()
        self.is_running = False
        logger.info("ã‚«ãƒ¡ãƒ©ã‚’åœæ­¢ã—ã¾ã—ãŸ")

# é¡”èªè­˜ + ç”»åƒåˆ†ææ©Ÿèƒ½
def analyze_visitor(image):
    """
    è¨ªå•è€…ã‚’åˆ†æï¼ˆYOLO â†’ Ollama ã®é †åºã§å‡¦ç†ï¼‰
    
    Returns:
        dict: {
            'type': 'known' or 'unknown',
            'message': str,
            'details': dict
        }
    """
    global face_detector
    
    if image is None:
        return {
            'type': 'error',
            'message': 'ç”»åƒã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ',
            'details': {}
        }
    
    # Step 1: YOLOé¡”èªè­˜ï¼ˆæœ‰åŠ¹ãªå ´åˆï¼‰
    if CONFIG["use_face_detection"] and face_detector and face_detector.is_model_available():
        logger.info("YOLOé¡”èªè­˜ã‚’å®Ÿè¡Œä¸­...")
        face_result = face_detector.detect_known_faces(image)
        
        if face_result['has_known_faces']:
            # æ—¢çŸ¥ã®é¡”ãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆ
            known_faces = face_result['known_faces']
            if len(known_faces) == 1:
                user = known_faces[0]
                message = f"{user['name']}ã•ã‚“ãŒã„ã‚‰ã£ã—ã‚ƒã„ã¾ã—ãŸï¼ˆä¿¡é ¼åº¦: {user['confidence']:.1%}ï¼‰"
            else:
                names = [f"{face['name']}ã•ã‚“" for face in known_faces]
                message = f"{', '.join(names)}ãŒã„ã‚‰ã£ã—ã‚ƒã„ã¾ã—ãŸ"
            
            return {
                'type': 'known',
                'message': message,
                'details': {
                    'faces': known_faces,
                    'detection_frame': face_result['detection_frame']
                }
            }
    
    # Step 2: æœªçŸ¥ã®äººç‰© â†’ Ollamaåˆ†æ
    logger.info("æœªçŸ¥ã®è¨ªå•è€…ã®ãŸã‚ã€è©³ç´°åˆ†æã‚’å®Ÿè¡Œä¸­...")
    ollama_result = analyze_with_ollama(image)
    
    return {
        'type': 'unknown',
        'message': f"æœªçŸ¥ã®è¨ªå•è€…ã§ã™ã€‚{ollama_result}",
        'details': {
            'ollama_analysis': ollama_result
        }
    }

def analyze_with_ollama(image):
    """Ollamaã®GPUæ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã¦ç”»åƒåˆ†æ"""
    if image is None:
        return "ç”»åƒã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ"
    
    try:
        # ç”»åƒã‚’Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        _, buffer = cv2.imencode('.jpg', image)
        base64_image = base64.b64encode(buffer).decode('utf-8')
        
        # APIãƒªã‚¯ã‚¨ã‚¹ãƒˆæº–å‚™
        headers = {
            "Content-Type": "application/json",
        }
        
        payload = {
            "model": CONFIG["model_name"],
            "messages": [
                {"role": "system", "content": CONFIG["system_prompt"]},
                {"role": "user", 
                 "content": "ã“ã®ç”»åƒã«æ˜ ã£ã¦ã„ã‚‹äººç‰©ã«ã¤ã„ã¦èª¬æ˜ã—ã¦ãã ã•ã„ã€‚", 
                 "images": [base64_image]}
            ],
            "stream": False,
            "options": {
                "num_gpu": getattr(config, 'OLLAMA_GPU_LAYERS', -1),  # GPUä½¿ç”¨è¨­å®š
                "num_thread": 4,
            }
        }
        
        # APIãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡
        response = requests.post(CONFIG["api_url"], headers=headers, json=payload, timeout=30)
        
        if response.status_code == 200:
            result = response.json()
            content = result["message"]["content"]
            logger.info(f"Ollamaåˆ†æçµæœ: {content}")
            return content
        else:
            error_message = f"APIé€šä¿¡ã‚¨ãƒ©ãƒ¼: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰ {response.status_code}"
            logger.error(error_message)
            return error_message
            
    except Exception as e:
        error_message = f"ç”»åƒåˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        logger.error(error_message)
        return error_message

# éŸ³å£°å‡ºåŠ›æ©Ÿèƒ½
def speak_text(text):
    """ãƒ†ã‚­ã‚¹ãƒˆã‚’éŸ³å£°ã«å¤‰æ›ï¼ˆOSã”ã¨ã«é©åˆ‡ãªæ–¹æ³•ã§ï¼‰"""
    if not text:
        return False
        
    logger.info(f"éŸ³å£°å‡ºåŠ›: {text}")
    
    try:
        success = False
        
        # OSã”ã¨ã®éŸ³å£°åˆæˆã‚³ãƒãƒ³ãƒ‰
        if sys.platform == 'darwin':  # macOS
            os.system(f'say "{text}"')
            success = True
        elif sys.platform == 'linux':  # Linux
            # espeakã€Open JTalkã€ã¾ãŸã¯ãã®ä»–ã®TTSãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹å ´åˆ
            if os.system('which espeak > /dev/null 2>&1') == 0:
                os.system(f'espeak -v ja "{text}"')
                success = True
            elif os.system('which open_jtalk > /dev/null 2>&1') == 0:
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¦å®Ÿè¡Œ
                with open('/tmp/speech.txt', 'w') as f:
                    f.write(text)
                os.system('open_jtalk -x /usr/local/dic -m /usr/local/voice/mei/mei_normal.htsvoice -ow /tmp/speech.wav /tmp/speech.txt')
                os.system('aplay /tmp/speech.wav')
                success = True
        elif sys.platform == 'win32':  # Windows
            # PowerShellã‚’ä½¿ç”¨
            os.system(f'powershell -Command "Add-Type -AssemblyName System.Speech; (New-Object System.Speech.Synthesis.SpeechSynthesizer).Speak(\'{text}\')"')
            success = True
            
        # Pythonãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ãŸéŸ³å£°åˆæˆï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
        if not success:
            try:
                import pyttsx3
                engine = pyttsx3.init()
                engine.say(text)
                engine.runAndWait()
                success = True
            except Exception as e:
                logger.error(f"pyttsx3ã§ã®éŸ³å£°åˆæˆã‚¨ãƒ©ãƒ¼: {e}")
                
        # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®å‡ºåŠ›ï¼ˆæœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
        if not success:
            logger.warning(f"éŸ³å£°åˆæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦å‡ºåŠ›ã—ã¾ã™: {text}")
            print(f"\n==== éŸ³å£°å‡ºåŠ› ====\n{text}\n==================\n")
            
        return success
    except Exception as e:
        logger.error(f"éŸ³å£°åˆæˆã‚¨ãƒ©ãƒ¼: {e}")
        return False

# ãƒ•ãƒ¬ãƒ¼ãƒ ã‚­ãƒ£ãƒ—ãƒãƒ£ã‚¹ãƒ¬ãƒƒãƒ‰
def frame_capture_thread():
    """ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ã—ç¶šã‘ã‚‹"""
    global camera, frame_buffer, current_frame
    
    logger.info("ãƒ•ãƒ¬ãƒ¼ãƒ ã‚­ãƒ£ãƒ—ãƒãƒ£ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’é–‹å§‹")
    
    while camera and camera.is_running:
        frame = camera.get_frame()
        if frame is not None:
            # ç¾åœ¨ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã¨ãƒãƒƒãƒ•ã‚¡ã‚’æ›´æ–°
            current_frame = frame.copy()
            timestamp = datetime.now()
            frame_buffer.append((timestamp, frame.copy()))
            
            # å¤ã„ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚¯ãƒªã‚¢
            while len(frame_buffer) > 0:
                oldest_time = frame_buffer[0][0]
                if (timestamp - oldest_time).total_seconds() > 10:  # 10ç§’ä»¥ä¸Šå‰ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã¯å‰Šé™¤
                    frame_buffer.popleft()
                else:
                    break
        
        # å°‘ã—å¾…æ©Ÿ
        time.sleep(0.1)
    
    logger.info("ãƒ•ãƒ¬ãƒ¼ãƒ ã‚­ãƒ£ãƒ—ãƒãƒ£ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’çµ‚äº†")

# ãƒ“ãƒ‡ã‚ªã‚¹ãƒˆãƒªãƒ¼ãƒ ç”Ÿæˆ
def generate_frames():
    """MJPEGå½¢å¼ã®ãƒ“ãƒ‡ã‚ªã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’ç”Ÿæˆ"""
    global current_frame, stream_active
    
    while stream_active:
        if current_frame is not None:
            # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’JPEGå½¢å¼ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
            frame = current_frame.copy()
            _, buffer = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, CONFIG["stream_quality"]])
            frame_bytes = buffer.tobytes()
            
            # MJPEGã‚¹ãƒˆãƒªãƒ¼ãƒ ã®ãƒ‘ãƒ¼ãƒˆ
            yield (b'--frame\r\n'
                   b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
        else:
            # ãƒ•ãƒ¬ãƒ¼ãƒ ãŒãªã„å ´åˆã¯ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ç”»åƒã‚’é€ä¿¡
            placeholder = np.ones((480, 640, 3), dtype=np.uint8) * 240
            cv2.putText(placeholder, "No Camera Feed", (180, 240), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)
            _, buffer = cv2.imencode('.jpg', placeholder)
            frame_bytes = buffer.tobytes()
            
            yield (b'--frame\r\n'
                   b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
            
        # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆã®èª¿æ•´
        time.sleep(1.0 / CONFIG["frame_rate"])

# å‘¼ã³éˆ´å‡¦ç†é–¢æ•°
def process_doorbell():
    """å‘¼ã³éˆ´ãŒæŠ¼ã•ã‚ŒãŸã¨ãã®å‡¦ç†ï¼ˆYOLOâ†’Ollamaçµ±åˆç‰ˆï¼‰"""
    global is_processing, last_result, frame_buffer
    
    is_processing = True
    logger.info("å‘¼ã³éˆ´å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™")
    
    try:
        # éŸ³å£°é€šçŸ¥
        speak_text("è¨ªå•è€…ã‚’ç¢ºèªã—ã¦ã„ã¾ã™ã€‚å°‘ã€…ãŠå¾…ã¡ãã ã•ã„ã€‚")
        
        # ã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’è€ƒæ…®ã—ã¦ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’é¸æŠ
        target_time = datetime.now() + timedelta(seconds=CONFIG["time_offset"])
        selected_frame = None
        
        if CONFIG["time_offset"] <= 0:
            # éå»ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æ¢ç´¢
            best_diff = float('inf')
            for timestamp, frame in frame_buffer:
                time_diff = abs((target_time - timestamp).total_seconds())
                if time_diff < best_diff:
                    best_diff = time_diff
                    selected_frame = frame.copy()
        else:
            # æœªæ¥ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å¾…ã¤
            wait_time = CONFIG["time_offset"]
            logger.info(f"{wait_time}ç§’å¾Œã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å¾…æ©Ÿä¸­...")
            time.sleep(wait_time)
            if current_frame is not None:
                selected_frame = current_frame.copy()
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ ãŒé¸æŠã§ããªã‹ã£ãŸå ´åˆã¯ç¾åœ¨ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½¿ç”¨
        if selected_frame is None:
            if current_frame is not None:
                selected_frame = current_frame.copy()
            else:
                speak_text("ç”»åƒã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                is_processing = False
                return "ç”»åƒã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ"
        
        # ä¿å­˜ç”¨ã«ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ä»˜ä¸
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # åˆ†æä¸­ã§ã‚ã‚‹ã“ã¨ã‚’è¡¨ç¤º
        analysis_frame = selected_frame.copy()
        cv2.putText(analysis_frame, "åˆ†æä¸­...", (20, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
        
        # YOLO + Ollamaçµ±åˆåˆ†æ
        result_data = analyze_visitor(selected_frame)
        result_message = result_data['message']
        last_result = result_message
        
        # ç”»åƒä¿å­˜
        if not os.path.exists("captures"):
            os.makedirs("captures")
        
        # æ¤œå‡ºçµæœã«ã‚ˆã£ã¦ä¿å­˜ã™ã‚‹ç”»åƒã‚’æ±ºå®š
        if result_data['type'] == 'known' and 'detection_frame' in result_data['details']:
            # YOLOæ¤œå‡ºçµæœä»˜ãã®ç”»åƒã‚’ä¿å­˜
            save_frame = result_data['details']['detection_frame']
        else:
            # å…ƒã®ç”»åƒã‚’ä¿å­˜
            save_frame = selected_frame
        
        cv2.imwrite(f"captures/analysis_{timestamp}.jpg", save_frame)
        
        # éŸ³å£°å‡ºåŠ›ï¼ˆçµæœã®ç¨®é¡ã«å¿œã˜ã¦ï¼‰
        if result_data['type'] == 'known':
            speak_text(result_message)
            speak_text("ã„ã‚‰ã£ã—ã‚ƒã„ã¾ã›ã€‚")
        elif result_data['type'] == 'unknown':
            speak_text("æœªçŸ¥ã®è¨ªå•è€…ã§ã™ã€‚")
            time.sleep(0.5)
            speak_text(result_data['details']['ollama_analysis'])
        else:
            speak_text("ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
        
        logger.info("å‘¼ã³éˆ´å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ")
        is_processing = False
        return result_message
        
    except Exception as e:
        error_message = f"å‘¼ã³éˆ´å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        logger.error(error_message)
        speak_text("å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
        is_processing = False
        return error_message

# HTMLã‚’ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªã§æä¾›
@app.route('/')
def index():
    """ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸"""
    # ç™»éŒ²æ¸ˆã¿ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‚’å–å¾—
    known_users = []
    face_detection_status = "ç„¡åŠ¹"
    
    if face_detector and face_detector.is_model_available():
        known_users = face_detector.get_known_users()
        face_detection_status = "æœ‰åŠ¹"
    
    html_content = f"""
<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>è¦–è¦šéšœå®³è€…å‘ã‘ç„é–¢è¨ªå•è€…èªè­˜ã‚·ã‚¹ãƒ†ãƒ  (YOLOçµ±åˆç‰ˆ)</title>
    <style>
        body {{
            font-family: sans-serif;
            max-width: 1000px;
            margin: 0 auto;
            padding: 20px;
        }}
        h1 {{
            text-align: center;
            margin-bottom: 20px;
        }}
        .container {{
            display: flex;
            flex-direction: column;
            gap: 20px;
        }}
        .camera-view {{
            width: 100%;
            text-align: center;
            margin-bottom: 20px;
            position: relative;
        }}
        #cameraStream {{
            max-width: 100%;
            border: 1px solid #ddd;
        }}
        .controls {{
            display: flex;
            justify-content: center;
            margin-bottom: 20px;
        }}
        .doorbell-button {{
            padding: 15px 30px;
            font-size: 18px;
            background-color: #4CAF50;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
        }}
        .doorbell-button:disabled {{
            background-color: #cccccc;
        }}
        .result-box {{
            border: 1px solid #ddd;
            padding: 15px;
            min-height: 100px;
            margin-bottom: 20px;
        }}
        .status {{
            text-align: center;
            margin-bottom: 20px;
            font-weight: bold;
        }}
        .button-row {{
            display: flex;
            justify-content: center;
            gap: 10px;
        }}
        .action-button {{
            padding: 10px 20px;
            background-color: #f5f5f5;
            border: 1px solid #ddd;
            border-radius: 4px;
            cursor: pointer;
        }}
        .config-row {{
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            margin-bottom: 10px;
            align-items: center;
        }}
        .config-label {{
            min-width: 180px;
        }}
        .overlay {{
            position: absolute;
            top: 10px;
            left: 10px;
            background-color: rgba(0, 0, 0, 0.5);
            color: white;
            padding: 5px 10px;
            border-radius: 4px;
        }}
        .system-info {{
            background-color: #f0f8ff;
            padding: 15px;
            border-radius: 5px;
            margin-bottom: 20px;
        }}
        .known-users {{
            background-color: #f5fff5;
            padding: 10px;
            border-radius: 5px;
            margin-top: 10px;
        }}
        .status-indicator {{
            display: inline-block;
            width: 10px;
            height: 10px;
            border-radius: 50%;
            margin-right: 5px;
        }}
        .status-active {{ background-color: #4CAF50; }}
        .status-inactive {{ background-color: #f44336; }}
    </style>
</head>
<body>
    <h1>è¦–è¦šéšœå®³è€…å‘ã‘ç„é–¢è¨ªå•è€…èªè­˜ã‚·ã‚¹ãƒ†ãƒ  (YOLOçµ±åˆç‰ˆ)</h1>
    
    <div class="container">
        <div class="system-info">
            <h3>ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹</h3>
            <p><span class="status-indicator {'status-active' if face_detection_status == 'æœ‰åŠ¹' else 'status-inactive'}"></span>YOLOé¡”èªè­˜: {face_detection_status}</p>
            <p><span class="status-indicator status-active"></span>Ollamaåˆ†æ: æœ‰åŠ¹ (GPUä½¿ç”¨)</p>
            {'<div class="known-users"><strong>ç™»éŒ²æ¸ˆã¿ãƒ¦ãƒ¼ã‚¶ãƒ¼:</strong> ' + ', '.join(known_users) + '</div>' if known_users else '<div class="known-users">ç™»éŒ²æ¸ˆã¿ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã„ã¾ã›ã‚“</div>'}
        </div>
        
        <div class="status" id="statusText">ã‚·ã‚¹ãƒ†ãƒ æº–å‚™å®Œäº†</div>
        
        <div class="camera-view">
            <img id="cameraStream" src="/video_feed" alt="ã‚«ãƒ¡ãƒ©æ˜ åƒ">
            <div class="overlay" id="fpsInfo">FPS: 0</div>
        </div>
        
        <div class="controls">
            <button id="doorbellButton" class="doorbell-button">ğŸ”” å‘¼ã³éˆ´ã‚’æŠ¼ã™</button>
        </div>
        
        <div>
            <h2>åˆ†æçµæœ</h2>
            <div id="resultBox" class="result-box">
                ã“ã“ã«åˆ†æçµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™
            </div>
            <div class="button-row">
                <button id="speakButton" class="action-button">çµæœã‚’èª­ã¿ä¸Šã’ã‚‹</button>
                <button id="captureButton" class="action-button">ç¾åœ¨ã®ç”»åƒã‚’ä¿å­˜</button>
            </div>
        </div>
        
        <div>
            <h2>è¨­å®š</h2>
            <div class="config-row">
                <span class="config-label">æ™‚é–“ã‚ªãƒ•ã‚»ãƒƒãƒˆ:</span>
                <input type="range" id="timeOffsetSlider" min="-5" max="5" value="0" step="1">
                <span id="timeOffsetValue">0ç§’</span>
                <span>(è² ï¼šéå»ã€æ­£ï¼šæœªæ¥)</span>
            </div>
            <div class="config-row">
                <span class="config-label">ã‚¹ãƒˆãƒªãƒ¼ãƒ å“è³ª:</span>
                <input type="range" id="qualitySlider" min="30" max="100" value="75" step="5">
                <span id="qualityValue">75%</span>
            </div>
            <div class="config-row">
                <span class="config-label">ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆ:</span>
                <input type="range" id="frameRateSlider" min="1" max="10" value="3" step="1">
                <span id="frameRateValue">3 FPS</span>
            </div>
            <div class="config-row">
                <span class="config-label">é¡”èªè­˜ä½¿ç”¨:</span>
                <input type="checkbox" id="useFaceDetection" {'checked' if CONFIG['use_face_detection'] else ''}>
                <span>æ—¢çŸ¥ã®äººç‰©ã‚’è‡ªå‹•èªè­˜</span>
            </div>
        </div>
        
        <div class="button-row">
            <button id="restartButton" class="action-button">ã‚·ã‚¹ãƒ†ãƒ å†èµ·å‹•</button>
            <button id="shutdownButton" class="action-button">ã‚·ã‚¹ãƒ†ãƒ åœæ­¢</button>
        </div>
    </div>

    <script>
        // DOMè¦ç´ 
        const statusText = document.getElementById('statusText');
        const cameraStream = document.getElementById('cameraStream');
        const doorbellButton = document.getElementById('doorbellButton');
        const resultBox = document.getElementById('resultBox');
        const speakButton = document.getElementById('speakButton');
        const captureButton = document.getElementById('captureButton');
        const restartButton = document.getElementById('restartButton');
        const shutdownButton = document.getElementById('shutdownButton');
        const timeOffsetSlider = document.getElementById('timeOffsetSlider');
        const timeOffsetValue = document.getElementById('timeOffsetValue');
        const qualitySlider = document.getElementById('qualitySlider');
        const qualityValue = document.getElementById('qualityValue');
        const frameRateSlider = document.getElementById('frameRateSlider');
        const frameRateValue = document.getElementById('frameRateValue');
        const useFaceDetection = document.getElementById('useFaceDetection');
        const fpsInfo = document.getElementById('fpsInfo');
        
        // çŠ¶æ…‹å¤‰æ•°
        let isProcessing = false;
        let frameCount = 0;
        let lastFpsUpdate = Date.now();
        
        // FPSè¨ˆæ¸¬
        function updateFps() {{
            const now = Date.now();
            const elapsed = (now - lastFpsUpdate) / 1000;
            
            if (elapsed > 1) {{  // 1ç§’ã”ã¨ã«æ›´æ–°
                const fps = Math.round(frameCount / elapsed);
                fpsInfo.textContent = `FPS: ${{fps}}`;
                frameCount = 0;
                lastFpsUpdate = now;
            }}
        }}
        
        // ã‚¹ãƒˆãƒªãƒ¼ãƒ ç”»åƒèª­ã¿è¾¼ã¿æ™‚ã®ã‚¤ãƒ™ãƒ³ãƒˆ
        cameraStream.onload = function() {{
            frameCount++;
            updateFps();
        }};
        
        // å‘¼ã³éˆ´ãƒœã‚¿ãƒ³
        doorbellButton.addEventListener('click', function() {{
            if (isProcessing) return;
            
            isProcessing = true;
            statusText.textContent = 'è¨ªå•è€…ç¢ºèªä¸­...';
            doorbellButton.disabled = true;
            
            fetch('/api/doorbell', {{
                method: 'POST'
            }})
            .then(response => response.json())
            .then(data => {{
                if (!data.success) {{
                    alert(data.message || 'ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ');
                }}
            }})
            .catch(error => {{
                console.error('é€šä¿¡ã‚¨ãƒ©ãƒ¼:', error);
                alert('é€šä¿¡ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ');
                isProcessing = false;
                doorbellButton.disabled = false;
                statusText.textContent = 'ã‚¨ãƒ©ãƒ¼';
            }});
        }});
        
        // çµæœèª­ã¿ä¸Šã’ãƒœã‚¿ãƒ³
        speakButton.addEventListener('click', function() {{
            const text = resultBox.textContent;
            if (text && text !== 'ã“ã“ã«åˆ†æçµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™') {{
                fetch('/api/speak', {{
                    method: 'POST',
                    headers: {{
                        'Content-Type': 'application/json'
                    }},
                    body: JSON.stringify({{ text: text }})
                }})
                .catch(error => console.error('èª­ã¿ä¸Šã’ã‚¨ãƒ©ãƒ¼:', error));
            }}
        }});
        
        // ç”»åƒä¿å­˜ãƒœã‚¿ãƒ³
        captureButton.addEventListener('click', function() {{
            fetch('/api/capture', {{
                method: 'POST'
            }})
            .then(response => response.json())
            .then(data => {{
                if (data.success) {{
                    alert('ç”»åƒã‚’ä¿å­˜ã—ã¾ã—ãŸ: ' + data.filename);
                }} else {{
                    alert('ç”»åƒã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: ' + data.error);
                }}
            }})
            .catch(error => console.error('ä¿å­˜ã‚¨ãƒ©ãƒ¼:', error));
        }});
        
        // å†èµ·å‹•ãƒœã‚¿ãƒ³
        restartButton.addEventListener('click', function() {{
            if (confirm('ã‚·ã‚¹ãƒ†ãƒ ã‚’å†èµ·å‹•ã—ã¾ã™ã‹ï¼Ÿ')) {{
                fetch('/api/restart', {{
                    method: 'POST'
                }})
                .then(response => response.json())
                .then(data => {{
                    alert(data.message || 'ã‚·ã‚¹ãƒ†ãƒ ã‚’å†èµ·å‹•ã—ã¦ã„ã¾ã™...');
                    setTimeout(() => {{
                        window.location.reload();
                    }}, 3000);
                }})
                .catch(error => console.error('å†èµ·å‹•ã‚¨ãƒ©ãƒ¼:', error));
            }}
        }});
        
        // åœæ­¢ãƒœã‚¿ãƒ³
        shutdownButton.addEventListener('click', function() {{
            if (confirm('ã‚·ã‚¹ãƒ†ãƒ ã‚’åœæ­¢ã—ã¾ã™ã‹ï¼Ÿ')) {{
                fetch('/api/shutdown', {{
                    method: 'POST'
                }})
                .then(response => response.json())
                .then(data => {{
                    alert(data.message || 'ã‚·ã‚¹ãƒ†ãƒ ã‚’åœæ­¢ã—ã¾ã—ãŸ');
                    statusText.textContent = 'åœæ­¢ä¸­';
                    doorbellButton.disabled = true;
                }})
                .catch(error => console.error('åœæ­¢ã‚¨ãƒ©ãƒ¼:', error));
            }}
        }});
        
        // æ™‚é–“ã‚ªãƒ•ã‚»ãƒƒãƒˆã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼
        timeOffsetSlider.addEventListener('input', function() {{
            const value = this.value;
            timeOffsetValue.textContent = `${{value}}ç§’`;
            updateConfig('time_offset', parseInt(value));
        }});
        
        // ç”»è³ªã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼
        qualitySlider.addEventListener('input', function() {{
            const value = this.value;
            qualityValue.textContent = `${{value}}%`;
            updateConfig('stream_quality', parseInt(value));
        }});
        
        // ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼
        frameRateSlider.addEventListener('input', function() {{
            const value = this.value;
            frameRateValue.textContent = `${{value}} FPS`;
            updateConfig('frame_rate', parseInt(value));
        }});
        
        // é¡”èªè­˜ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹
        useFaceDetection.addEventListener('change', function() {{
            updateConfig('use_face_detection', this.checked);
        }});
        
        // è¨­å®šæ›´æ–°é–¢æ•°
        function updateConfig(key, value) {{
            fetch('/api/config', {{
                method: 'POST',
                headers: {{
                    'Content-Type': 'application/json'
                }},
                body: JSON.stringify({{
                    key: key,
                    value: value
                }})
            }})
            .catch(error => console.error('è¨­å®šæ›´æ–°ã‚¨ãƒ©ãƒ¼:', error));
        }}
        
        // ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°
        function updateStatus() {{
            fetch('/api/status')
            .then(response => response.json())
            .then(data => {{
                // ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°
                statusText.textContent = data.status;
                isProcessing = data.processing;
                doorbellButton.disabled = isProcessing;
                
                // çµæœæ›´æ–°
                if (data.result) {{
                    resultBox.textContent = data.result;
                }}
            }})
            .catch(error => {{
                console.error('ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼:', error);
            }});
        }}
        
        // ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆ
        document.addEventListener('keydown', function(e) {{
            // ã‚¹ãƒšãƒ¼ã‚¹ã‚­ãƒ¼ã§å‘¼ã³éˆ´
            if (e.code === 'Space' && !isProcessing) {{
                doorbellButton.click();
                e.preventDefault();
            }}
        }});
        
        // è¨­å®šå€¤ã®åˆæœŸè¡¨ç¤º
        fetch('/api/config')
        .then(response => response.json())
        .then(data => {{
            timeOffsetSlider.value = data.time_offset;
            timeOffsetValue.textContent = `${{data.time_offset}}ç§’`;
            
            qualitySlider.value = data.stream_quality;
            qualityValue.textContent = `${{data.stream_quality}}%`;
            
            frameRateSlider.value = data.frame_rate;
            frameRateValue.textContent = `${{data.frame_rate}} FPS`;
            
            useFaceDetection.checked = data.use_face_detection;
        }})
        .catch(error => console.error('è¨­å®šå–å¾—ã‚¨ãƒ©ãƒ¼:', error));
        
        // å®šæœŸçš„ãªçŠ¶æ…‹æ›´æ–°
        updateStatus();
        setInterval(updateStatus, 1000);
    </script>
</body>
</html>
    """
    
    # ç›´æ¥HTMLæ–‡å­—åˆ—ã‚’è¿”ã™
    return Response(html_content, content_type='text/html; charset=utf-8')

# ãƒ“ãƒ‡ã‚ªãƒ•ã‚£ãƒ¼ãƒ‰
@app.route('/video_feed')
def video_feed():
    """ãƒ“ãƒ‡ã‚ªã‚¹ãƒˆãƒªãƒ¼ãƒ ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    return Response(generate_frames(),
                    mimetype='multipart/x-mixed-replace; boundary=frame')

@app.route('/api/doorbell', methods=['POST'])
def doorbell():
    """å‘¼ã³éˆ´API"""
    global is_processing
    
    if is_processing:
        return jsonify({
            'success': False,
            'message': 'åˆ¥ã®å‡¦ç†ãŒå®Ÿè¡Œä¸­ã§ã™'
        })
    
    # éåŒæœŸã§å‡¦ç†
    threading.Thread(target=process_doorbell, daemon=True).start()
    
    return jsonify({
        'success': True,
        'message': 'è¨ªå•è€…ç¢ºèªã‚’é–‹å§‹ã—ã¾ã—ãŸ'
    })

@app.route('/api/status', methods=['GET'])
def status():
    """ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹API"""
    global is_processing, last_result
    
    return jsonify({
        'status': 'åˆ†æä¸­...' if is_processing else 'æº–å‚™å®Œäº†',
        'processing': is_processing,
        'result': last_result if last_result else None
    })

@app.route('/api/speak', methods=['POST'])
def speak():
    """ãƒ†ã‚­ã‚¹ãƒˆèª­ã¿ä¸Šã’API"""
    if not request.json or 'text' not in request.json:
        return jsonify({'success': False, 'error': 'ãƒ†ã‚­ã‚¹ãƒˆãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“'}), 400
    
    text = request.json['text']
    success = speak_text(text)
    
    return jsonify({
        'success': success,
        'message': 'éŸ³å£°å‡ºåŠ›ã‚’å®Ÿè¡Œã—ã¾ã—ãŸ' if success else 'éŸ³å£°å‡ºåŠ›ã«å¤±æ•—ã—ã¾ã—ãŸ'
    })

@app.route('/api/capture', methods=['POST'])
def capture():
    """ç¾åœ¨ã®ç”»åƒã‚’ä¿å­˜"""
    global current_frame
    
    if current_frame is None:
        return jsonify({
            'success': False,
            'error': 'ç”»åƒãŒã‚ã‚Šã¾ã›ã‚“'
        })
    
    try:
        # ä¿å­˜ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        if not os.path.exists("captures"):
            os.makedirs("captures")
            
        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãã®ãƒ•ã‚¡ã‚¤ãƒ«å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"captures/manual_{timestamp}.jpg"
        
        # ç”»åƒä¿å­˜
        cv2.imwrite(filename, current_frame)
        
        return jsonify({
            'success': True,
            'filename': filename
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/config', methods=['GET', 'POST'])
def config_api():
    """è¨­å®šå–å¾—ãƒ»æ›´æ–°API"""
    if request.method == 'GET':
        # è¨­å®šå–å¾—
        return jsonify({
            'time_offset': CONFIG["time_offset"],
            'stream_quality': CONFIG["stream_quality"],
            'frame_rate': CONFIG["frame_rate"],
            'use_face_detection': CONFIG["use_face_detection"],
        })
    else:
        # è¨­å®šæ›´æ–°
        if not request.json or 'key' not in request.json or 'value' not in request.json:
            return jsonify({'success': False, 'error': 'è¨­å®šã‚­ãƒ¼ã¨å€¤ãŒå¿…è¦ã§ã™'}), 400
            
        key = request.json['key']
        value = request.json['value']
        
        if key in ['time_offset', 'stream_quality', 'frame_rate', 'use_face_detection']:
            CONFIG[key] = value
            
            # ã‚«ãƒ¡ãƒ©ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆã‚’æ›´æ–°
            if key == 'frame_rate' and camera:
                camera.frame_rate = value
                
            logger.info(f"è¨­å®šã‚’æ›´æ–°ã—ã¾ã—ãŸ: {key} = {value}")
            return jsonify({
                'success': True,
                'message': f"è¨­å®šã‚’æ›´æ–°ã—ã¾ã—ãŸ: {key} = {value}"
            })
        else:
            return jsonify({
                'success': False,
                'error': f"ä¸æ˜ãªè¨­å®šã‚­ãƒ¼: {key}"
            }), 400

@app.route('/api/restart', methods=['POST'])
def restart():
    """ã‚·ã‚¹ãƒ†ãƒ å†èµ·å‹•API"""
    global camera, stream_active
    
    try:
        # ã‚«ãƒ¡ãƒ©ã¨ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’åœæ­¢
        stream_active = False
        if camera and camera.is_running:
            camera.stop()
        
        # å†èµ·å‹•å‡¦ç†ï¼ˆéåŒæœŸï¼‰
        def restart_process():
            time.sleep(1)
            os.execv(sys.executable, [sys.executable] + sys.argv)
        
        threading.Thread(target=restart_process, daemon=True).start()
        
        return jsonify({
            'success': True,
            'message': 'ã‚·ã‚¹ãƒ†ãƒ ã‚’å†èµ·å‹•ã—ã¦ã„ã¾ã™...'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'å†èµ·å‹•ã‚¨ãƒ©ãƒ¼: {str(e)}'
        }), 500

@app.route('/api/shutdown', methods=['POST'])
def shutdown():
    """ã‚·ã‚¹ãƒ†ãƒ åœæ­¢API"""
    global camera, stream_active
    
    try:
        # ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’åœæ­¢
        stream_active = False
        
        # ã‚«ãƒ¡ãƒ©ã‚’åœæ­¢
        if camera and camera.is_running:
            camera.stop()
        
        # åœæ­¢ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        speak_text("ã‚·ã‚¹ãƒ†ãƒ ã‚’åœæ­¢ã—ã¾ã™ã€‚")
        
        return jsonify({
            'success': True,
            'message': 'ã‚·ã‚¹ãƒ†ãƒ ã‚’åœæ­¢ã—ã¾ã—ãŸ'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'åœæ­¢ã‚¨ãƒ©ãƒ¼: {str(e)}'
        }), 500

# ãƒ¡ã‚¤ãƒ³å‡¦ç†
def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    global camera, face_detector
    
    try:
        # YOLOé¡”èªè­˜ã®åˆæœŸåŒ–
        if CONFIG["use_face_detection"] and FaceDetector:
            face_detector = FaceDetector()
            if face_detector.is_model_available():
                logger.info("YOLOé¡”èªè­˜ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
                known_users = face_detector.get_known_users()
                if known_users:
                    logger.info(f"ç™»éŒ²æ¸ˆã¿ãƒ¦ãƒ¼ã‚¶ãƒ¼: {', '.join(known_users)}")
                else:
                    logger.info("ç™»éŒ²æ¸ˆã¿ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã„ã¾ã›ã‚“")
            else:
                logger.warning("YOLOãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚é¡”èªè­˜æ©Ÿèƒ½ã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¾ã™")
        else:
            logger.info("é¡”èªè­˜æ©Ÿèƒ½ã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™")
        
        # ã‚«ãƒ¡ãƒ©ã®åˆæœŸåŒ–
        camera = RealtimeCamera(
            use_camera=CONFIG["use_camera"], 
            camera_id=CONFIG["camera_id"],
            frame_rate=CONFIG["frame_rate"]
        )
        
        if not camera.start():
            logger.error("ã‚«ãƒ¡ãƒ©ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚­ãƒ£ãƒ—ãƒãƒ£ã‚¹ãƒ¬ãƒƒãƒ‰ã®é–‹å§‹
        capture_thread = threading.Thread(target=frame_capture_thread, daemon=True)
        capture_thread.start()
        
        # èµ·å‹•ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        logger.info("ã‚·ã‚¹ãƒ†ãƒ ãŒèµ·å‹•ã—ã¾ã—ãŸ")
        if face_detector and face_detector.is_model_available():
            speak_text("YOLOçµ±åˆç„é–¢è¨ªå•è€…èªè­˜ã‚·ã‚¹ãƒ†ãƒ ãŒèµ·å‹•ã—ã¾ã—ãŸã€‚é¡”èªè­˜æ©Ÿèƒ½ãŒæœ‰åŠ¹ã§ã™ã€‚")
        else:
            speak_text("ç„é–¢è¨ªå•è€…èªè­˜ã‚·ã‚¹ãƒ†ãƒ ãŒèµ·å‹•ã—ã¾ã—ãŸã€‚Ollamaåˆ†ææ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
        
        # Flaskã‚µãƒ¼ãƒãƒ¼èµ·å‹•
        app.run(host='0.0.0.0', port=8080, debug=False, threaded=True)
        
    except KeyboardInterrupt:
        logger.info("ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰å‰²ã‚Šè¾¼ã¿ã«ã‚ˆã‚Šã‚·ã‚¹ãƒ†ãƒ ã‚’çµ‚äº†ã—ã¾ã™")
    except Exception as e:
        logger.error(f"ã‚·ã‚¹ãƒ†ãƒ èµ·å‹•ã‚¨ãƒ©ãƒ¼: {e}")
    finally:
        # çµ‚äº†å‡¦ç†
        global stream_active
        stream_active = False
        
        if camera and camera.is_running:
            camera.stop()
        logger.info("ã‚·ã‚¹ãƒ†ãƒ ã‚’çµ‚äº†ã—ã¾ã—ãŸ")

if __name__ == "__main__":
    main()